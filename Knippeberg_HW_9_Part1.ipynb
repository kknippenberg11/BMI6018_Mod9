{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "\n",
    "#%% Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b61215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>flight</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>517.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N14228</td>\n",
       "      <td>1545</td>\n",
       "      <td>EWR</td>\n",
       "      <td>IAH</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>533.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N24211</td>\n",
       "      <td>1714</td>\n",
       "      <td>LGA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1416</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>542.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>N619AA</td>\n",
       "      <td>1141</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MIA</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1089</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>544.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N804JB</td>\n",
       "      <td>725</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BQN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1576</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>554.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N668DN</td>\n",
       "      <td>461</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>116.0</td>\n",
       "      <td>762</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>554.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N39463</td>\n",
       "      <td>1696</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ORD</td>\n",
       "      <td>150.0</td>\n",
       "      <td>719</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N516JB</td>\n",
       "      <td>507</td>\n",
       "      <td>EWR</td>\n",
       "      <td>FLL</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1065</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>557.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N829AS</td>\n",
       "      <td>5708</td>\n",
       "      <td>LGA</td>\n",
       "      <td>IAD</td>\n",
       "      <td>53.0</td>\n",
       "      <td>229</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>557.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N593JB</td>\n",
       "      <td>79</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MCO</td>\n",
       "      <td>140.0</td>\n",
       "      <td>944</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>558.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>N3ALAA</td>\n",
       "      <td>301</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>138.0</td>\n",
       "      <td>733</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year  month  day  dep_time  dep_delay  arr_time  arr_delay  \\\n",
       "0           1  2013      1    1     517.0        2.0     830.0       11.0   \n",
       "1           2  2013      1    1     533.0        4.0     850.0       20.0   \n",
       "2           3  2013      1    1     542.0        2.0     923.0       33.0   \n",
       "3           4  2013      1    1     544.0       -1.0    1004.0      -18.0   \n",
       "4           5  2013      1    1     554.0       -6.0     812.0      -25.0   \n",
       "5           6  2013      1    1     554.0       -4.0     740.0       12.0   \n",
       "6           7  2013      1    1     555.0       -5.0     913.0       19.0   \n",
       "7           8  2013      1    1     557.0       -3.0     709.0      -14.0   \n",
       "8           9  2013      1    1     557.0       -3.0     838.0       -8.0   \n",
       "9          10  2013      1    1     558.0       -2.0     753.0        8.0   \n",
       "\n",
       "  carrier tailnum  flight origin dest  air_time  distance  hour  minute  \n",
       "0      UA  N14228    1545    EWR  IAH     227.0      1400   5.0    17.0  \n",
       "1      UA  N24211    1714    LGA  IAH     227.0      1416   5.0    33.0  \n",
       "2      AA  N619AA    1141    JFK  MIA     160.0      1089   5.0    42.0  \n",
       "3      B6  N804JB     725    JFK  BQN     183.0      1576   5.0    44.0  \n",
       "4      DL  N668DN     461    LGA  ATL     116.0       762   5.0    54.0  \n",
       "5      UA  N39463    1696    EWR  ORD     150.0       719   5.0    54.0  \n",
       "6      B6  N516JB     507    EWR  FLL     158.0      1065   5.0    55.0  \n",
       "7      EV  N829AS    5708    LGA  IAD      53.0       229   5.0    57.0  \n",
       "8      B6  N593JB      79    JFK  MCO     140.0       944   5.0    57.0  \n",
       "9      AA  N3ALAA     301    LGA  ORD     138.0       733   5.0    58.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #%% Importing Data\n",
    "flights_data_df = pd.read_csv('flights.csv') #I prefer to call these \"df\" for dataframe and \"arr\" for array. This command creates a dataframe from the CSV\n",
    "weather_data_df = pd.read_csv('weather.csv') #importing weather csv as a dataframe\n",
    "weather_data_arr = weather_data_df.to_numpy() #this command converts the dataframe to a numpy 2-D array\n",
    "flights_data_df.head(10) #Gives the first few rows (5 by default; 10 in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e71571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 336776 entries, 0 to 336775\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  336776 non-null  int64  \n",
      " 1   year        336776 non-null  int64  \n",
      " 2   month       336776 non-null  int64  \n",
      " 3   day         336776 non-null  int64  \n",
      " 4   dep_time    328521 non-null  float64\n",
      " 5   dep_delay   328521 non-null  float64\n",
      " 6   arr_time    328063 non-null  float64\n",
      " 7   arr_delay   327346 non-null  float64\n",
      " 8   carrier     336776 non-null  object \n",
      " 9   tailnum     334264 non-null  object \n",
      " 10  flight      336776 non-null  int64  \n",
      " 11  origin      336776 non-null  object \n",
      " 12  dest        336776 non-null  object \n",
      " 13  air_time    327346 non-null  float64\n",
      " 14  distance    336776 non-null  int64  \n",
      " 15  hour        328521 non-null  float64\n",
      " 16  minute      328521 non-null  float64\n",
      "dtypes: float64(7), int64(6), object(4)\n",
      "memory usage: 43.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8719 entries, 0 to 8718\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  8719 non-null   int64  \n",
      " 1   origin      8719 non-null   object \n",
      " 2   year        8719 non-null   int64  \n",
      " 3   month       8718 non-null   float64\n",
      " 4   day         8718 non-null   float64\n",
      " 5   hour        8718 non-null   float64\n",
      " 6   temp        8718 non-null   float64\n",
      " 7   dewp        8718 non-null   float64\n",
      " 8   humid       8718 non-null   float64\n",
      " 9   wind_dir    8486 non-null   float64\n",
      " 10  wind_speed  8718 non-null   float64\n",
      " 11  wind_gust   8718 non-null   float64\n",
      " 12  precip      8719 non-null   float64\n",
      " 13  pressure    7780 non-null   float64\n",
      " 14  visib       8719 non-null   float64\n",
      "dtypes: float64(12), int64(2), object(1)\n",
      "memory usage: 1021.9+ KB\n",
      "class:  ndarray\n",
      "shape:  (8719, 15)\n",
      "strides:  (8, 69752)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  False\n",
      "fortran:  True\n",
      "data pointer: 0x7c48e8000\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: object\n"
     ]
    }
   ],
   "source": [
    "#But i am also interested in the data types, number of records, etc. in the flights and weather dfs. If we turned the weather df into an array, I'm guessing all the data types are the same, but I'm going to check nonetheless with \"info\" on the dataframe.\n",
    "flights_data_df.info()\n",
    "weather_data_df.info() #This is the DATAFRAME before it is turned into an array.\n",
    "np.info(weather_data_arr) #And this is the ARRAY."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b69928",
   "metadata": {},
   "source": [
    "%% Pandas Data Filtering/Sorting Question Answering\n",
    "(use flights_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b070aacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_1: There were 2113 flights from JFK to SLC.\n"
     ]
    }
   ],
   "source": [
    "# #Question 1 How many flights were there from JFK to SLC? Int\n",
    "\n",
    "flights_orgn_dest = flights_data_df[[\"origin\",\"dest\"]] #Though not strictly necessary, limiting the dataset to just origin and destination\n",
    "num_flights_jfk_slc = flights_orgn_dest[(flights_orgn_dest[\"origin\"]==\"JFK\") & (flights_orgn_dest[\"dest\"]==\"SLC\")] #FILTERING for origins that are \"JFK\" and destinations that are \"SLC\"\n",
    "print(f\"q_1: There were {len(num_flights_jfk_slc)} flights from JFK to SLC.\") #the length of the filtered dataframe gives us the number of rows/records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf874ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_2: There are 2 airlines that fly into SLC: DL and B6.\n"
     ]
    }
   ],
   "source": [
    "# #Question 2 How many airlines fly to SLC? Should be int\n",
    "\n",
    "flights_dest_slc = flights_data_df[(flights_data_df[\"dest\"] == \"SLC\")] #Filtering the \"dest\" column for flights into SLC\n",
    "unique_airlines = flights_dest_slc[\"carrier\"].unique() #Taking the filtered df and applying the \"unique\" method to the \"carrier\" column to get unique carriers.\n",
    "print(f\"q_2: There are {len(unique_airlines)} airlines that fly into SLC: {unique_airlines[0]} and {unique_airlines[1]}.\")#the length of the filtered dataframe gives us the number of rows/records, and we retrieve the values at indexes 0 and 1, the only two values in the series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74f5791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_3: The average arrival delay for flights to RDU is 10.05 minutes.\n"
     ]
    }
   ],
   "source": [
    "# #Question 3 What is the average arrival delay for flights to RDU? float\n",
    "\n",
    "flights_to_rdu = flights_data_df[(flights_data_df[\"dest\"] == \"RDU\")]#Filtering the \"dest\" column for flights into RDU\n",
    "rdu_avg_arr_delay = flights_to_rdu[\"arr_delay\"].mean() #Taking the filtered df and applying the \"mean\" method to the \"arr_delay\" column to find the mean/average arrival delay within the filtered flights.\n",
    "print(f\"q_3: The average arrival delay for flights to RDU is {round(rdu_avg_arr_delay,2)} minutes.\") #Rounding the answer to 2 decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841d5863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_4: Of the 3923 flights to SEA, 2092, or 53.33%, come from New York airports LGA or JFK.\n"
     ]
    }
   ],
   "source": [
    "# #Question 4 What proportion of flights to SEA come from the two NYC airports (LGA and JFK)?  float\n",
    "flights_to_sea = flights_data_df[(flights_data_df[\"dest\"] == \"SEA\")]#Filtering the \"dest\" column for flights into SEA\n",
    "flights_from_NYC = flights_to_sea[(flights_to_sea[\"origin\"] == \"LGA\") | (flights_to_sea[\"origin\"] == \"JFK\")] #filtering flights to SEA for flights from 2 NYC airports, JFK OR LGA\n",
    "print(f\"q_4: Of the {len(flights_to_sea)} flights to SEA, {len(flights_from_NYC)}, or {(len(flights_from_NYC)/len(flights_to_sea)):.2%}, come from New York airports LGA or JFK.\") #the length of the final filtered dataframes gives us the number flights, and dividing the lengths gives us the proportion of flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c97d126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_5: The maximum average departure delay, of 83.54 minutes, occurs on 2013/3/8.\n"
     ]
    }
   ],
   "source": [
    "# #Question 5 Which date has the largest average depature delay? Pd slice with date and float\n",
    "# #please make date a column. Preferred format is 2013/1/1 (y/m/d)\n",
    "\n",
    "flights_w_date = flights_data_df.copy() #Now we are going to fundamentally change something about the flights_data_df dataframe, so I'm going to make a copy of it to work with, so the original remains unchanged.\n",
    "flights_w_date['year'] = flights_w_date['year'].astype(str) #Because what we're going to do is CONCATENATE year, month, and day to create a new 'date' column, and so first, they have to be converted from integers to strings.\n",
    "flights_w_date['month'] = flights_w_date['month'].astype(str)\n",
    "flights_w_date['day'] = flights_w_date['day'].astype(str)\n",
    "flights_w_date['date'] = flights_w_date['year'] + '/' + flights_w_date['month'] + '/' + flights_w_date['day'] #This is the line that CONCATENATES the three to make a new 'date' column.\n",
    "\n",
    "avg_dep_delay_by_date = flights_w_date.groupby(['date'], as_index = False)['dep_delay'].mean() #Here is where we finally start answering Question 5. We DON'T FILTER, though the ([ is still used. We group by the numerous records with the same date, and then we mean all the dep_delays for each date. Making as_index = False is command 1 of 2 to ensure that we can retrieve date VALUES rather than index positions.\n",
    "\n",
    "dd_max = avg_dep_delay_by_date['dep_delay'].max() #Here we get the MAXIMUM average departure delay (and can thus find its corresponding date too)\n",
    "print(f\"q_5: The maximum average departure delay, of {round(dd_max, 2)} minutes, occurs on {avg_dep_delay_by_date[avg_dep_delay_by_date['dep_delay'] == dd_max]['date'].values[0]}.\") #okay. the dd_max is the maximum number of minutes (as a float, rather than a datetime, but whatever). And to retrieve the date, we filter so that we can isolate the 'date' of dd_max, AND this is command 2 of 2 to ensure we get the VALUE rather than the index position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7576f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_6: The maximum average arrival delay, of 85.86 minutes, occurs on 2013/3/8.\n"
     ]
    }
   ],
   "source": [
    "# #Question 6 Which date has the largest average arrival delay? pd slice with date and float\n",
    "avg_arr_delay_by_date = flights_w_date.groupby(['date'], as_index = False)['arr_delay'].mean() #Thank goodness, this Question is just like Question 5, except with arrival delays. Mostly just substituting \"arr\" for \"dep\"\n",
    "\n",
    "ad_max = avg_arr_delay_by_date['arr_delay'].max()\n",
    "print(f\"q_6: The maximum average arrival delay, of {round(ad_max, 2)} minutes, occurs on {avg_arr_delay_by_date[avg_arr_delay_by_date['arr_delay'] == ad_max]['date'].values[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da05d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_7: Of the flights departing LGA or JFK, flight number N666DN flew the fastest, at 11.72 mpm.\n"
     ]
    }
   ],
   "source": [
    "# #Question 7 Which flight departing LGA or JFK in 2013 flew the fastest? pd slice with tailnumber and speed\n",
    "# #speed = distance/airtime\n",
    "\n",
    "flights_LGA_JFK_2013 = flights_data_df.copy() #I'm going to answer this one by adding a \"speed\" column, so I'm making a copy of the original df to work with, again.\n",
    "flights_LGA_JFK_2013 = flights_LGA_JFK_2013[(flights_LGA_JFK_2013['origin'] == \"LGA\") | (flights_LGA_JFK_2013['origin'] == \"JFK\")] #Classic filtering ... note that ALL flights have a year of 2013, so I didn't filter for that. \n",
    "flights_LGA_JFK_2013['speed'] = flights_LGA_JFK_2013['distance']/flights_LGA_JFK_2013['air_time'] #adding that speed column, with air_fime (not airtime) as the denominator\n",
    "max_speed = flights_LGA_JFK_2013['speed'].max() #We've seen this before\n",
    "print(f\"q_7: Of the flights departing LGA or JFK, flight number {flights_LGA_JFK_2013[flights_LGA_JFK_2013['speed'] == max_speed]['tailnum'].values[0]} flew the fastest, at {round(max_speed, 2)} mpm.\") #Here again, we are reporting the tail number 'tailnum' of the fastest flight, and we're using .values[0] to get the VALUE instead of the index position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83336107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_8: \n",
      "The following columns in the original weather_data_df have a corresponding number of NaN values:\n",
      "Unnamed: 0      0\n",
      "origin          0\n",
      "year            0\n",
      "month           1\n",
      "day             1\n",
      "hour            1\n",
      "temp            1\n",
      "dewp            1\n",
      "humid           1\n",
      "wind_dir      233\n",
      "wind_speed      1\n",
      "wind_gust       1\n",
      "precip          0\n",
      "pressure      939\n",
      "visib           0\n",
      "dtype: int64 \n",
      "\n",
      "The following columns in the new weather_data_df (renamed weather_data_zero) have a corresponding number of NaN values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# #Question 8 Replace all nans in the weather pd dataframe with 0s. Pd with no nans\n",
    "\n",
    "NaN_values = weather_data_df.isna().sum() #I first compared the results using .isna() versus .isnull() and of course they were the same, but since it's NaN you want, I wanted to be precise in usage.\n",
    "\n",
    "for v in weather_data_df.isna():\n",
    "    weather_data_zero = weather_data_df[v] == 0 #This means for each value in the dataframe that is NaN, change it to zero and save it as a new dataframe. \n",
    "\n",
    "print(\"q_8: \\nThe following columns in the original weather_data_df have a corresponding number of NaN values:\")\n",
    "print(NaN_values, \"\\n\")\n",
    "\n",
    "print(\"The following columns in the new weather_data_df (renamed weather_data_zero) have a corresponding number of NaN values:\")\n",
    "print(weather_data_zero.isna().sum()) #I used \".isna().sum()\" to succinctly show NaN values present in the original dataset and absent in the new dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee34a49",
   "metadata": {},
   "source": [
    "%% Numpy Data Filtering/Sorting Question Answering\n",
    "(Use weather_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4fbda13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_9: A total of 671 observations were made in February.\n"
     ]
    }
   ],
   "source": [
    "# #Question 9 How many observations were made in Feburary? Int\n",
    "\n",
    "month_col = weather_data_arr[:,3] #returns the 'month' column of the original array. 'month_col' is also an array.\n",
    "feb_obs = np.where(month_col == 2) #using np.where returns a TUPLE CONTAINING AN ARRAY OF INDEX POSITIONS WHERE VALUE IS 2. So within the tuple, there is literally 1 array, which is why if we were to do len(feb_obs), we would get an answer of 1.\n",
    "print(f\"q_9: A total of {len(feb_obs[0])} observations were made in February.\") #THIS allows us to find the length of the array [position 0] within the tuple feb_obs. we want to count the number of index positions within the array, the array itself being index 0, as it's the only thing in the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f09f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_10: The average humidity for February was 62.92%.\n"
     ]
    }
   ],
   "source": [
    "# #Question 10 What was the mean for humidity in February? Float\n",
    "feb_mask = weather_data_arr[:,3] == 2 # I suppose this is another way to get a 1-D Boolean mask to lay over a 2-D array. I wanted to make sure the other 'columns' in the array were accessible to me after I filtered for February. \n",
    "weather_data_feb = weather_data_arr[feb_mask] #this ensures that we have all the columns and are not just isolating the 'month' column\n",
    "average_humidity = np.mean(weather_data_feb[:,8], axis=0) #because with our february filtered array, we want the mean humidity, but NOT the mean of all the columns, some of which are object datatypes anyway. Axis = the dimensions that are being averaged. 0 means columns, 1 means rows.\n",
    "print(f\"q_10: The average humidity for February was {round(average_humidity,2)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e71d03dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_11: The standard deviation for humidity in February was 20.34%.\n"
     ]
    }
   ],
   "source": [
    "# #Question 11 What was the std for humidity in February? Float\n",
    "std_humidity = np.std(weather_data_feb[:,8], axis=0) #Thank goodness this is just like Question 10, except with std instead of mean.\n",
    "print(f\"q_11: The standard deviation for humidity in February was {round(std_humidity,2)}%.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvenv314",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
